# El arte de conversar con ChatGPT (y otros LLMs)

*Publicado el 30 de junio de 2023*

ü¶ë You can read this post in [english](../en/blog/how-talk-with-chatgpt.html).

üêô Podes ler este post em [portugu√™s](../pt/blogue/como-falar-com-chatgpt.html).

![Rachael y el Voight-Kampff test](../img/chatgpt-rachael.jpg)

En un intercambio de correos electr√≥nicos sobre ChatGPT, un colega me pregunt√≥ cu√°l ser√≠a la mejor forma de escribir prompts al desarrollar c√≥digo. Bueno, la respuesta no es simple, despu√©s de todo esto implica conversar con una red neuronal y muchas veces ya es dif√≠cil hacerlo con otras personas, cuanto m√°s con una m√°quina. Sin embargo, como soy una persona muy educada y que siempre le gusta ayudar cuando es posible, reflexion√© y respond√≠ de la mejor manera que pude.

La red est√° llena [consejos](https://github.com/readme/guides/coding-generative-ai) para mejorar nuestros prompts y he incorporado muchos de ellos, pero al analizarlos individualmente, no s√© qu√© grado de mejora han tra√≠do. Incluso hay algunos en los que no estoy seguro de si tuvieron un impacto significativo. Es normal, la experiencia que acumulo todav√≠a no es suficiente para hacer estad√≠stica. Sin embargo, lo que puedo afirmar es que en conjunto y en comparaci√≥n con mis toscas primeras pruebas, su incorporaci√≥n ha resultado en una mejora innegable en los resultados obtenidos.

Un caso diferente son las estrategias enfocadas en la resoluci√≥n de tareas m√°s complejas, ya que a diferencia de las simples en las que podemos obtener una respuesta v√°lida e incluso muy similar, usando o no un determinado consejo, la adopci√≥n de estas t√©cnicas trae una mejora inmediata y evidente. [Sin una estrategia definida](https://xulioze.com/blog/construir-pwa-con-chatgpt.html), el LLM tend√≠a a dispersarse y cometer errores, oblig√°ndome a corregirlo y guarlo con nuevas preguntas o instrucciones. Sin embargo, cuando inclu√≠ en mi trabajo el [Chain-of-Thought](https://www.promptingguide.ai/es/techniques/cot) y el [Generated Knowledge](https://www.promptingguide.ai/es/techniques/knowledge), estos problemas se resolvieron. (Tengo pendiente un art√≠culo contando c√≥mo desarroll√© un blog en React con la ayuda de ChatGPT).

> "Understanding these capabilities are important to understand the limitations of these models and how to use them effectively."
>
> ‚Äî *Prompt Engineering Guide*

Entonces, ¬øc√≥mo evaluamos los peque√±os consejos que encontramos en la red? Un enfoque inicial (y obvio) es seguir las indicaciones de fuentes confiables. A m√≠ me gusta mucho [learnprompting.org](https://learnprompting.org/) y [promptingguide.ai](https://www.promptingguide.ai/es), pero [hay muchas m√°s](https://github.com/openai/openai-cookbook#prompting-guides). Otro, complementario, es determinar si el prop√≥sito de un consejo tiene sentido con el funcionamiento de los LLM. Es evidente que seguir este enfoque implica un gasto extra de tiempo, ya que:

1. Tenemos que determinar el prop√≥sito del consejo, aunque todos tiendan a buscar:
   - Reducir el [n√∫mero de tokens](https://platform.openai.com/tokenizer) utilizados en las preguntas y respuestas.
   - Optimizar el trabajo del LLM en el procesamiento de las preguntas y en la generaci√≥n de las respuestas.
   - Obtener la mejor respuesta posible para nuestra tarea.

2. Y nos obliga a profundizar en la [comprensi√≥n y el conocimiento de estas herramientas](https://www.promptingguide.ai/es/models).

Sin embargo, esta siempre es una buena inversi√≥n, ya que ayuda a mejorar nuestro trabajo diario y nos permite disfrutar del placer de aprender algo nuevo.

Finalmente mi colega, que tambi√©n es muy educado, agradeci√≥ la respuesta. Pero como igualmente es pragm√°tico y directo, quiso despu√©s saber si yo hab√≠a identificado alguna buena pr√°ctica. Resumiendo, buscaba una lista de consejos üò¨

## Mis consejos

Dejo aqu√≠ las pr√°cticas que siempre incluyo en mis prompts orientados al desarrollo de tareas simples. Para aprender a escribir c√≥digo complejo con ChatGPT, te recomiendo comenzar por el art√≠culo "[An example of LLM prompting for programming](https://martinfowler.com/articles/2023-chatgpt-xu-hao.html)".

- Evito la formalidad. Nada de "Buenos d√≠as", "podr√≠a usted‚Ä¶", "muchas gracias", etc. No te preocupes, el LLM no es un ser consciente y siempre es bueno ahorrar algunos tokens.
- Siempre empiezo con un "As a [rol name]". Con esto busco formatear la respuesta del modelo de una manera m√°s espec√≠fica.
- Incluyo detalles con terminolog√≠a especializada. La idea es proporcionar suficiente contexto para evitar que el modelo tenga que adivinar lo que quiero decir.
- Procuro ser lo m√°s sint√©tico posible, en equilibrio con el punto anterior. Cuanto m√°s breve y directo sea nuestro prompt, m√°s concisa ser√° la respuesta, adem√°s de ahorrar algunos tokens.
- Limpio mis c√≥digos de ejemplo. Todo lo que no es necesario para desarrollar la tarea solo agrega ruido y desperdicia tokens.

Lo que pretend√≠a ser un borrador de un m√©todo para aprender a conversar con las m√°quinas se ha convertido en otro art√≠culo con consejos para usar ChatGPT. ¬øCrees que el prop√≥sito de cada uno tiene sentido con el funcionamiento de los LLMs?
